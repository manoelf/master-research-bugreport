{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src.modules.pipeline.balancing import Balancing\n",
    "from src.modules.pipeline.cross_validation import CrossValidation\n",
    "from src.modules.pipeline.finetunning import Finetunning\n",
    "from src.modules.preprocess.preprocess import Preprocess\n",
    "from src.modules.util.constant import Features, Model, ModelName as mn\n",
    "from src.modules.util.helper_metrics import MetricsHelper as mh\n",
    "from src.modules.util.util import Util as util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = Model.NB\n",
    "LG = Model.LG\n",
    "DT = Model.DT\n",
    "RF = Model.RF\n",
    "GB = Model.GB\n",
    "CV = Model.CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCE_PATH = '../data/balanced/balanced_data.csv'\n",
    "\n",
    "# data = pd.read_csv('../data/bg_results.csv', engine='python', quoting=3, header=0, sep='ยง')\n",
    "# data.drop(columns=Features.train_test_features, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame.copy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filing the null values whit empty string\n",
    "\n",
    "# data['summary'].fillna('', inplace=True)\n",
    "# data['total_words_summary'] = data.apply(lambda row: len(list(nltk.word_tokenize(row['summary']))), axis=1)\n",
    "\n",
    "# data['description'].fillna('', inplace=True)\n",
    "# data['total_words_description'] = data.apply(lambda row: len(list(nltk.word_tokenize(row['description']))), axis=1)\n",
    "\n",
    "# data.drop(columns=Features.features, inplace=True, axis=1)\n",
    "# data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_preprocess.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN, TEST = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For balancind the data the follwoing chunks must be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN = Balancing().oversample(TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TRAIN.drop('resolution', axis = 1)\n",
    "y_train = TRAIN['resolution']\n",
    "\n",
    "test = TEST.drop('resolution', axis=1)\n",
    "y_test = TEST['resolution']\n",
    "\n",
    "classes = TRAIN['resolution'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# text_columns = train.select_dtypes(include=['object']).columns\n",
    "# x_train_vectorized = vectorizer.fit_transform(train[text_columns])\n",
    "\n",
    "# text_columns = test.select_dtypes(include=['object']).columns\n",
    "# x_test_vectorized =  vectorizer.transform(test[text_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_vectorized = pd.DataFrame(x_test_vectorized.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "# x_train_vectorized = pd.DataFrame(x_train_vectorized.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_numeric = train.drop(text_columns, axis=1)\n",
    "# test_numeric = test.drop(text_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train_numeric.join(x_train_vectorized, lsuffix='_numeric', rsuffix='_vectorize')\n",
    "# x_test = test_numeric.join(x_test_vectorized, lsuffix='_numeric', rsuffix='_vectorize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train.fillna(0)\n",
    "# x_test = x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x_train[c].apply(lambda x: print(x, c) if (str(x).isalpha() and str(x) not in ['nan', 'True', 'False']) else None) for c in x_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (27351, 1277) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m NB_metrics \u001b[39m=\u001b[39m util()\u001b[39m.\u001b[39mget_metrics(NB, mn\u001b[39m.\u001b[39mNB, x_train, y_train, x_test, y_test, classes)\n",
      "File \u001b[0;32m~/manoel-ms/master-research-bugreport/src/modules/../../src/modules/util/util.py:63\u001b[0m, in \u001b[0;36mUtil.get_metrics\u001b[0;34m(self, model, model_name, x_train, y_train, x_test, y_test, classes)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_metrics\u001b[39m(\u001b[39mself\u001b[39m, model, model_name, x_train, y_train, x_test, y_test, classes):\n\u001b[1;32m     61\u001b[0m     initial_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 63\u001b[0m     model \u001b[39m=\u001b[39m tm()\u001b[39m.\u001b[39mtrain_model(model, x_train, y_train)\n\u001b[1;32m     64\u001b[0m     pred \u001b[39m=\u001b[39m tm()\u001b[39m.\u001b[39mpredict_model(model, x_test)\n\u001b[1;32m     66\u001b[0m     predicted_probabilities \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(x_test)[:, \u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/manoel-ms/master-research-bugreport/src/modules/../../src/modules/pipeline/training.py:9\u001b[0m, in \u001b[0;36mTainingModels.train_model\u001b[0;34m(self, model, x_train, y_train)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(\u001b[39mself\u001b[39m, model, x_train, y_train):\n\u001b[0;32m----> 9\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/naive_bayes.py:266\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 266\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(y\u001b[39m=\u001b[39my)\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_partial_fit(\n\u001b[1;32m    268\u001b[0m     X, y, np\u001b[39m.\u001b[39munique(y), _refit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sample_weight\u001b[39m=\u001b[39msample_weight\n\u001b[1;32m    269\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:568\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m--> 568\u001b[0m     y \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[1;32m    569\u001b[0m     out \u001b[39m=\u001b[39m y\n\u001b[1;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1143\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1142\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m-> 1143\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1144\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, estimator_name\u001b[39m=\u001b[39mestimator_name)\n\u001b[1;32m   1145\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1193\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1194\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA column-vector y was passed when a 1d array was\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected. Please change the shape of y to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1198\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[1;32m   1200\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_order(xp\u001b[39m.\u001b[39mreshape(y, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m, xp\u001b[39m=\u001b[39mxp)\n\u001b[0;32m-> 1202\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1203\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my should be a 1d array, got an array of shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shape)\n\u001b[1;32m   1204\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (27351, 1277) instead."
     ]
    }
   ],
   "source": [
    "NB_metrics = util().get_metrics(NB, mn.NB, x_train, y_train, x_test, y_test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG_metrics = util().get_metrics(LG, mn.LG, x_train, y_train, x_test, y_test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_metrics = util().get_metrics(DT, mn.DT, x_train, y_train, x_test, y_test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_metrics = util().get_metrics(RF, mn.RF, x_train, y_train, x_test, y_test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_metrics = util().get_metrics(GB, mn.GB, x_train, y_train, x_test, y_test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_cv = CrossValidation().get_cross_validation_result(NB, x_train, y_train)\n",
    "NB_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG_cv = CrossValidation().get_cross_validation_result(LG, x_train, y_train)\n",
    "LG_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_cv = CrossValidation().get_cross_validation_result(DT, x_train, y_train)\n",
    "DT_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_cv = CrossValidation().get_cross_validation_result(RF, x_train, y_train)\n",
    "RF_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_cv = CrossValidation().get_cross_validation_result(GB, x_train, y_train)\n",
    "GB_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_finetunning_NB, pred_NB = Finetunning().model_finetuning(NB, mn.NB, x_train, y_train, x_test, y_test, classes, '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/naive_bayers/NB_tuned_metrics.pkl', '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/naive_bayers/NB_pred.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_finetunning_LR, pred_LR = Finetunning().model_finetuning(LG, mn.LG, x_train, y_train, x_test, y_test, classes, '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/logistic_regression/LG_tuned_metrics.pkl', '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/logistic_regression/LG_pred.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_finetunning_DT, pred_DT = Finetunning().model_finetuning(DT, mn.DT, x_train, y_train, x_test, y_test, classes, '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/decision_tree/DT_tuned_metrics.pkl', '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/decision_tree/DT_pred.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_finetunning_RF, pred_RF = Finetunning().model_finetuning(RF, mn.RF, x_train, y_train, x_test, y_test, classes, '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/random_forest/RF_tuned_metrics.pkl', '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/random_forest/RF_pred.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_finetunning_GB, pred_GB = Finetunning().model_finetuning(GB, mn.GB, x_train, y_train, x_test, y_test, classes, '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/gradient_boosting/GB_tuned_metrics.pkl', '/home/lorena/manoel-ms/master-research-bugreport/src/data/models/gradient_boosting/GB_pred.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util().save_result(NB_metrics, NB_cv, mn.NB)\n",
    "# util().save_result(LG_metrics, LG_cv, mn.LG)\n",
    "# util().save_result(DT_metrics, DT_cv, mn.DT)\n",
    "# util().save_result(RF_metrics, RF_cv, mn.RF)\n",
    "# util().save_result(GB_metrics, GB_cv, mn.GB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
